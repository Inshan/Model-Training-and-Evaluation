{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  # For data manipulation and analysis\n",
    "import numpy as np   # For numerical operations\n",
    "from sklearn.model_selection import train_test_split  # For splitting the dataset\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder  # For data preprocessing\n",
    "from sklearn.linear_model import LogisticRegression  # Logistic Regression model\n",
    "from sklearn.ensemble import RandomForestClassifier  # Random Forest model\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score  # Evaluation metrics\n",
    "import tensorflow as tf  # For building Neural Network\n",
    "from tensorflow.keras.models import Sequential  # Sequential model for Neural Network\n",
    "from tensorflow.keras.layers import Dense  # Dense layer for Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "data = pd.read_csv(url)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_23304\\1411586650.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Age'].fillna(data['Age'].median(), inplace=True)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_23304\\1411586650.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Data Preprocessing\n",
    "# ------------------\n",
    "# Drop unnecessary columns that are not useful for prediction\n",
    "data = data.drop(['PassengerId', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "# Handle missing values\n",
    "\n",
    "# Fill missing 'Age' values with the median age\n",
    "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
    "\n",
    "# Fill missing 'Embarked' values with the most frequent value (mode)\n",
    "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Name      891 non-null    object \n",
      " 3   Sex       891 non-null    object \n",
      " 4   Age       891 non-null    float64\n",
      " 5   SibSp     891 non-null    int64  \n",
      " 6   Parch     891 non-null    int64  \n",
      " 7   Fare      891 non-null    float64\n",
      " 8   Embarked  891 non-null    object \n",
      "dtypes: float64(2), int64(4), object(3)\n",
      "memory usage: 62.8+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables to numerical using Label Encoding\n",
    "le = LabelEncoder()\n",
    "data['Sex'] = le.fit_transform(data['Sex'])  # Convert 'Sex' to numerical (0 for female, 1 for male)\n",
    "data['Embarked'] = le.fit_transform(data['Embarked'])  # Convert 'Embarked' to numerical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "# Features: All columns except 'Survived'\n",
    "# Target: 'Survived' column (0 = Did not survive, 1 = Survived)\n",
    "X = data.drop(['Survived','Name'], axis=1)\n",
    "y = data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features to have zero mean and unit variance\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)  # Fit and transform the training data\n",
    "X_test = scaler.transform(X_test)  # Transform the test data using the same scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dell\\Documents\\GitHub\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    }
   ],
   "source": [
    "# Model 1: Logistic Regression\n",
    "# ----------------------------\n",
    "lr_model = LogisticRegression(random_state=42)  # Initialize Logistic Regression model\n",
    "lr_model.fit(X_train, y_train)  # Train the model on the training data\n",
    "y_pred_lr = lr_model.predict(X_test)  # Predict on the test data\n",
    "\n",
    "# Model 2: Random Forest\n",
    "# ----------------------\n",
    "rf_model = RandomForestClassifier(random_state=42)  # Initialize Random Forest model\n",
    "rf_model.fit(X_train, y_train)  # Train the model on the training data\n",
    "y_pred_rf = rf_model.predict(X_test)  # Predict on the test data\n",
    "\n",
    "# Model 3: Neural Network\n",
    "# -----------------------\n",
    "# Initialize a Sequential Neural Network model\n",
    "nn_model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),  # Input layer with 64 neurons\n",
    "    Dense(32, activation='relu'),  # Hidden layer with 32 neurons\n",
    "    Dense(1, activation='sigmoid')  # Output layer with 1 neuron (binary classification)\n",
    "])\n",
    "# Compile the model with Adam optimizer and binary cross-entropy loss\n",
    "nn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# Train the model for 50 epochs with a batch size of 32\n",
    "nn_model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=0)\n",
    "# Predict on the test data (convert probabilities to binary predictions)\n",
    "y_pred_nn = (nn_model.predict(X_test) > 0.5).astype(int).flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model Performance\n",
    "# --------------------------\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    \"\"\"\n",
    "    Evaluate the performance of a model using accuracy, precision, recall, and F1-score.\n",
    "    \n",
    "    Parameters:\n",
    "    - y_true: True labels\n",
    "    - y_pred: Predicted labels\n",
    "    - model_name: Name of the model (for printing purposes)\n",
    "    \n",
    "    Returns:\n",
    "    - Tuple containing accuracy, precision, recall, and F1-score\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)  # Calculate accuracy\n",
    "    precision = precision_score(y_true, y_pred)  # Calculate precision\n",
    "    recall = recall_score(y_true, y_pred)  # Calculate recall\n",
    "    f1 = f1_score(y_true, y_pred)  # Calculate F1-score\n",
    "    \n",
    "    # Print the evaluation metrics\n",
    "    print(f\"{model_name} Metrics:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1-Score: {f1:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Metrics:\n",
      "Accuracy: 0.8045\n",
      "Precision: 0.7826\n",
      "Recall: 0.7297\n",
      "F1-Score: 0.7552\n",
      "------------------------------\n",
      "Random Forest Metrics:\n",
      "Accuracy: 0.8212\n",
      "Precision: 0.8088\n",
      "Recall: 0.7432\n",
      "F1-Score: 0.7746\n",
      "------------------------------\n",
      "Neural Network Metrics:\n",
      "Accuracy: 0.8268\n",
      "Precision: 0.8413\n",
      "Recall: 0.7162\n",
      "F1-Score: 0.7737\n",
      "------------------------------\n",
      "                 Model  Accuracy  Precision    Recall  F1-Score\n",
      "0  Logistic Regression  0.804469   0.782609  0.729730  0.755245\n",
      "1        Random Forest  0.821229   0.808824  0.743243  0.774648\n",
      "2       Neural Network  0.826816   0.841270  0.716216  0.773723\n"
     ]
    }
   ],
   "source": [
    "# Evaluate all models\n",
    "lr_metrics = evaluate_model(y_test, y_pred_lr, \"Logistic Regression\")\n",
    "rf_metrics = evaluate_model(y_test, y_pred_rf, \"Random Forest\")\n",
    "nn_metrics = evaluate_model(y_test, y_pred_nn, \"Neural Network\")\n",
    "\n",
    "# Compare Model Performance\n",
    "# -------------------------\n",
    "# Create a DataFrame to compare the performance of all models\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Random Forest', 'Neural Network'],\n",
    "    'Accuracy': [lr_metrics[0], rf_metrics[0], nn_metrics[0]],\n",
    "    'Precision': [lr_metrics[1], rf_metrics[1], nn_metrics[1]],\n",
    "    'Recall': [lr_metrics[2], rf_metrics[2], nn_metrics[2]],\n",
    "    'F1-Score': [lr_metrics[3], rf_metrics[3], nn_metrics[3]]\n",
    "})\n",
    "\n",
    "# Print the comparison table\n",
    "print(metrics_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
